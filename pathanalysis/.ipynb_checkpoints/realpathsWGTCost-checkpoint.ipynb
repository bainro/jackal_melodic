{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad58ead5-9a85-4349-bab0-8dae622cb7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "import scipy.stats as stats\n",
    "from utils import get_distance, haversineDistance\n",
    "from placecell import PlaceNetwork, loadNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd77b6a-9c0a-40e8-b0fe-d3df849b5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR = 'paths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0221890e-d11f-4676-a58f-99cc49d79d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_tailed_t_test(array1, array2, alternative='greater'):\n",
    "    \"\"\"\n",
    "    Perform a one-tailed t-test on two arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - array1, array2: The two arrays for which the t-test will be performed.\n",
    "    - alternative: The direction of the test. It can be 'greater' or 'less'.\n",
    "    \n",
    "    Returns:\n",
    "    - t_statistic: The t-statistic of the test.\n",
    "    - p_value: The p-value of the test.\n",
    "    \"\"\"\n",
    "    _, p_value = stats.ttest_ind(array1, array2)\n",
    "    \n",
    "    if alternative == 'greater':\n",
    "        t_statistic = p_value / 2  # Divide p-value by 2 for a one-tailed test\n",
    "    elif alternative == 'less':\n",
    "        t_statistic = 1 - p_value / 2  # Subtract p-value divided by 2 from 1\n",
    "    else:\n",
    "        raise ValueError(\"Invalid alternative. Use 'greater' or 'less'.\")\n",
    "\n",
    "    result = {\n",
    "        'statistic': t_statistic,\n",
    "        'p_value': p_value,\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def wilcoxon_ranksum_test(data1, data2):\n",
    "    statistic, p_value = stats.ranksums(data1, data2)\n",
    "\n",
    "    result = {\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83bcb6b-ea86-4a96-894e-f11f8a0b87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToTuple(input_string):\n",
    "    try:\n",
    "        tuples_list = eval(input_string)\n",
    "        \n",
    "        if isinstance(tuples_list, list) and all(isinstance(t, tuple) and len(t) == 2 for t in tuples_list):\n",
    "            return tuples_list\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input format. Must be a list of tuples.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error converting string to tuples: {}\".format(str(e)))\n",
    "\n",
    "def evalCost(input_string):\n",
    "    try:\n",
    "        # Using eval to parse the string into a Python expression\n",
    "        list_of_lists = eval(input_string)\n",
    "        \n",
    "        # Check if the result is a list of lists\n",
    "        if isinstance(list_of_lists, list) and all(isinstance(sublist, list) for sublist in list_of_lists):\n",
    "            # Check if each element in the sublists is a float\n",
    "            flattened_list = [elem for sublist in list_of_lists for elem in sublist]\n",
    "            return list_of_lists\n",
    "        else:\n",
    "            raise ValueError(\"Invalid input format. Must be a list of lists.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "        raise ValueError(\"Error converting string to list of lists: {}\".format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991b5602-0380-490e-bf57-75e29a48374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = os.listdir(PATH_DIR)\n",
    "\n",
    "paths = {'RRT' : {}, 'spike' : {}, 'astar' : {}}\n",
    "start_ends = []\n",
    "\n",
    "for file in dir_list:\n",
    "    if os.path.isdir(os.path.join(PATH_DIR, file)):\n",
    "        continue\n",
    "    comps = file[0:-4].split(\"_\")\n",
    "    \n",
    "    pathtype = comps[0]\n",
    "    \n",
    "    start = comps[1].split(\"-\")\n",
    "    start = (int(start[0]), int(start[1]))\n",
    "\n",
    "    end = comps[2].split(\"-\")\n",
    "    end = (int(end[0]), int(end[1]))\n",
    "\n",
    "    point = ((start, end))\n",
    "\n",
    "    with open(os.path.join(PATH_DIR, file)) as f:\n",
    "        path = stringToTuple(f.readline())\n",
    "        costs = evalCost(f.readline())\n",
    "        if costs != None:\n",
    "            paths[pathtype][point] = {'trajectory' : None, 'cost' : None}\n",
    "            paths[pathtype][point]['trajectory'] = path\n",
    "            paths[pathtype][point]['cost'] = costs\n",
    "\n",
    "    if point not in start_ends and costs != None:\n",
    "        start_ends.append(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c102cae6-42e6-49e3-a4f0-0b39bc7eeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateCost(data):\n",
    "    current_total = 0\n",
    "    current_time = 0\n",
    "\n",
    "    obstacle_total = 0\n",
    "    obstacle_time = 0\n",
    "\n",
    "    slope_total = 0\n",
    "    slope_time = 0\n",
    "\n",
    "    time_total = 0\n",
    "\n",
    "    for wp in data:\n",
    "        current_total += wp[1]\n",
    "        current_time += wp[2]\n",
    "        obstacle_total += wp[3]\n",
    "        obstacle_time += wp[4]\n",
    "        slope_total += wp[5]\n",
    "        slope_time += wp[6]\n",
    "\n",
    "        time_total += wp[0] \n",
    "\n",
    "    return [current_total, current_time, obstacle_total, obstacle_time, slope_total, slope_time, time_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7587f6cc-4b78-4080-b893-5b106834ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrts = []\n",
    "swps = []\n",
    "astars = []\n",
    "\n",
    "rrt_plens = []\n",
    "swp_plens = []\n",
    "astar_plens = []\n",
    "\n",
    "for pts in start_ends:\n",
    "    rrt_costs = paths['RRT'][pts]['cost']\n",
    "    swp_costs = paths['spike'][pts]['cost']\n",
    "    astar_costs = paths['astar'][pts]['cost']\n",
    "\n",
    "    rrts.append(calculateCost(rrt_costs))\n",
    "    swps.append(calculateCost(swp_costs))\n",
    "    astars.append(calculateCost(astar_costs))\n",
    "\n",
    "    rrt_plens.append(len(paths['RRT'][pts]['trajectory']))\n",
    "    swp_plens.append(len(paths['spike'][pts]['trajectory']))\n",
    "    astar_plens.append(len(paths['astar'][pts]['trajectory']))\n",
    "\n",
    "if len(rrts) != len(swps):\n",
    "    print(\"Number of data not the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e70e333-9465-4be6-a042-0b4adf22fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = PlaceNetwork()\n",
    "n.initAldritch(numcosts=6)\n",
    "n.initConnections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a04070-3469-4f82-8a28-5a23e9815902",
   "metadata": {},
   "outputs": [],
   "source": [
    "rrt_dists = []\n",
    "swp_dists = []\n",
    "astar_dists = []\n",
    "\n",
    "for pts in start_ends:\n",
    "    rrt = paths['RRT'][pts]['trajectory']\n",
    "    swp = paths['spike'][pts]['trajectory']\n",
    "    astar = paths['astar'][pts]['trajectory']\n",
    "\n",
    "    rrt_d = 0\n",
    "    swp_d = 0\n",
    "    astar_d = 0\n",
    "\n",
    "    for i in range(len(rrt) - 1):\n",
    "        d1 = n.cells[n.points[rrt[i]]].origin\n",
    "        d2 = n.cells[n.points[rrt[i+1]]].origin\n",
    "\n",
    "        rrt_d += haversineDistance(d1[0], d1[1], d2[0], d2[1])\n",
    "\n",
    "    rrt_dists.append(rrt_d)\n",
    "\n",
    "    for i in range(len(swp) - 1):\n",
    "        d1 = n.cells[n.points[swp[i]]].origin\n",
    "        d2 = n.cells[n.points[swp[i+1]]].origin\n",
    "    \n",
    "        swp_d += haversineDistance(d1[0], d1[1], d2[0], d2[1])\n",
    "\n",
    "    swp_dists.append(swp_d)\n",
    "\n",
    "    for i in range(len(astar) - 1):\n",
    "        d1 = n.cells[n.points[astar[i]]].origin\n",
    "        d2 = n.cells[n.points[astar[i+1]]].origin\n",
    "    \n",
    "        astar_d += haversineDistance(d1[0], d1[1], d2[0], d2[1])\n",
    "\n",
    "    astar_dists.append(astar_d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f188400-b546-402f-885d-f9824a3d311f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiking wavefront versus rrt\n",
      "Mean swp distance: 46.60400973848205\n",
      "Mean rrt distance: 60.24742640545722\n",
      "p-value: 0.01125063503687932\n"
     ]
    }
   ],
   "source": [
    "distance_rrt = one_tailed_t_test(swp_dists, rrt_dists, alternative='less')\n",
    "print(\"Spiking wavefront versus rrt\")\n",
    "print(f\"Mean swp distance: {np.mean(swp_dists)}\")\n",
    "print(f\"Mean rrt distance: {np.mean(rrt_dists)}\")\n",
    "print(f\"p-value: {distance_rrt['p_value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663d44b8-213c-4bb7-9b26-1c269b272b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spiking wavefront versus astar\n",
      "Mean swp distance: 46.60400973848205\n",
      "Mean astar distance: 46.981456232882294\n",
      "p-value: 0.9141730835079851\n"
     ]
    }
   ],
   "source": [
    "distance_astar = one_tailed_t_test(swp_dists, astar_dists, alternative='less')\n",
    "print(\"Spiking wavefront versus astar\")\n",
    "print(f\"Mean swp distance: {np.mean(swp_dists)}\")\n",
    "print(f\"Mean astar distance: {np.mean(astar_dists)}\")\n",
    "print(f\"p-value: {distance_astar['p_value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803df19a-fc85-439f-9814-a00889550027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean swp current: 415.8916010531817\n",
      "Mean rrt current: 468.7360005084618\n",
      "p-value: 0.33805456112219867\n",
      "___________________________________________\n",
      "Mean swp obstacle: 2.0644825549312027\n",
      "Mean rrt obstacle: 4.446772594980196\n",
      "p-value: 0.00683539044199596\n",
      "___________________________________________\n",
      "Mean swp slope: 7.570660604121381\n",
      "Mean rrt slope: 7.522386438607012\n",
      "p-value: 0.9236900389913347\n"
     ]
    }
   ],
   "source": [
    "swp_curr = [swps[i][0] / swps[i][1] * (swps[i][6]) for i in range(len(swps))]\n",
    "rrt_curr = [rrts[i][0] / rrts[i][1] * (rrts[i][6]) for i in range(len(rrts))]\n",
    "\n",
    "swp_obs = [swps[i][2] / swps[i][3] * 100 for i in range(len(swps))]\n",
    "rrt_obs = [rrts[i][2] / rrts[i][3] * 100 for i in range(len(rrts))]\n",
    "\n",
    "swp_slope = [np.rad2deg(swps[i][4] / swps[i][5]) for i in range(len(swps))]\n",
    "rrt_slope = [np.rad2deg(rrts[i][4] / rrts[i][5]) for i in range(len(rrts))]\n",
    "\n",
    "curr_result_rrt = one_tailed_t_test(swp_curr, rrt_curr, alternative='less')\n",
    "print(f\"Mean swp current: {np.mean(swp_curr)}\")\n",
    "print(f\"Mean rrt current: {np.mean(rrt_curr)}\")\n",
    "print(f\"p-value: {curr_result_rrt['p_value']}\")\n",
    "\n",
    "print(\"___________________________________________\")\n",
    "\n",
    "obs_result_rrt = one_tailed_t_test(swp_obs, rrt_obs, alternative='less')\n",
    "print(f\"Mean swp obstacle: {np.mean(swp_obs)}\")\n",
    "print(f\"Mean rrt obstacle: {np.mean(rrt_obs)}\")\n",
    "print(f\"p-value: {obs_result_rrt['p_value']}\")\n",
    "\n",
    "print(\"___________________________________________\")\n",
    "\n",
    "slope_result_rrt = one_tailed_t_test(swp_slope, rrt_slope, alternative='less')\n",
    "print(f\"Mean swp slope: {np.mean(swp_slope)}\")\n",
    "print(f\"Mean rrt slope: {np.mean(rrt_slope)}\")\n",
    "print(f\"p-value: {slope_result_rrt['p_value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5c0aea8-a589-4077-93ad-21bfa6b050a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean swp total current: 415.8916010531817\n",
      "Mean astar total current: 382.82136479279393\n",
      "p-value: 0.42934023512360453\n",
      "___________________________________________\n",
      "Mean swp total obstacle: 2.0644825549312027\n",
      "Mean astar total obstacle: 3.9517479700044476\n",
      "p-value: 0.029877626817600384\n",
      "___________________________________________\n",
      "Mean swp total slope: 7.570660604121381\n",
      "Mean astar total slope: 7.723805713953298\n",
      "p-value: 0.7919961492454977\n"
     ]
    }
   ],
   "source": [
    "swp_curr = [swps[i][0] / swps[i][1] * (swps[i][6]) for i in range(len(swps))]\n",
    "astar_curr = [astars[i][0] / astars[i][1] * (astars[i][6]) for i in range(len(astars))]\n",
    "\n",
    "swp_obs = [swps[i][2] / swps[i][3] * 100 for i in range(len(swps))]\n",
    "astar_obs = [astars[i][2] / astars[i][3] * 100 for i in range(len(astars))]\n",
    "\n",
    "swp_slope = [np.rad2deg(swps[i][4] / swps[i][5]) for i in range(len(swps))]\n",
    "astar_slope = [np.rad2deg(astars[i][4] / astars[i][5]) for i in range(len(astars))]\n",
    "\n",
    "curr_result_astar = one_tailed_t_test(swp_curr, astar_curr, alternative='less')\n",
    "print(f\"Mean swp total current: {np.mean(swp_curr)}\")\n",
    "print(f\"Mean astar total current: {np.mean(astar_curr)}\")\n",
    "print(f\"p-value: {curr_result_astar['p_value']}\")\n",
    "\n",
    "print(\"___________________________________________\")\n",
    "\n",
    "obs_result_astar = one_tailed_t_test(swp_obs, astar_obs, alternative='less')\n",
    "print(f\"Mean swp total obstacle: {np.mean(swp_obs)}\")\n",
    "print(f\"Mean astar total obstacle: {np.mean(astar_obs)}\")\n",
    "print(f\"p-value: {obs_result_astar['p_value']}\")\n",
    "\n",
    "print(\"___________________________________________\")\n",
    "\n",
    "slope_result_astar = one_tailed_t_test(swp_slope, astar_slope, alternative='less')\n",
    "print(f\"Mean swp total slope: {np.mean(swp_slope)}\")\n",
    "print(f\"Mean astar total slope: {np.mean(astar_slope)}\")\n",
    "print(f\"p-value: {slope_result_astar['p_value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b177df2d-da41-492f-b98d-e34c2b75c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT (atar, rrt)\n",
      "(array([False, False]), array([0.85868047, 0.67610912]), 0.025320565519103666, 0.025)\n",
      "___________________________________________\n",
      "OBSTACLE (atar, rrt)\n",
      "(array([False,  True]), array([0.05975525, 0.01367078]), 0.025320565519103666, 0.025)\n",
      "___________________________________________\n",
      "SLOPE (atar, rrt)\n",
      "(array([False, False]), array([1., 1.]), 0.025320565519103666, 0.025)\n",
      "___________________________________________\n",
      "DISTANCE (atar, rrt)\n",
      "(array([False,  True]), array([1.        , 0.02250127]), 0.025320565519103666, 0.025)\n",
      "___________________________________________\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "all_curr = [i['p_value'] for i in [curr_result_astar, curr_result_rrt]]\n",
    "all_obs = [i['p_value'] for i in [obs_result_astar, obs_result_rrt]]\n",
    "all_slope = [i['p_value'] for i in [slope_result_astar, slope_result_rrt]]\n",
    "all_distance = [i['p_value'] for i in [distance_astar, distance_rrt]]\n",
    "\n",
    "curr_corr = multipletests(all_curr, alpha=0.05, method='bonferroni')\n",
    "print(\"CURRENT (atar, rrt)\")\n",
    "print(curr_corr)\n",
    "print(\"___________________________________________\")\n",
    "obs_corr = multipletests(all_obs, alpha=0.05, method='bonferroni')\n",
    "print(\"OBSTACLE (atar, rrt)\")\n",
    "print(obs_corr)\n",
    "print(\"___________________________________________\")\n",
    "slope_corr = multipletests(all_slope, alpha=0.05, method='bonferroni')\n",
    "print(\"SLOPE (atar, rrt)\")\n",
    "print(slope_corr)\n",
    "print(\"___________________________________________\")\n",
    "distance_corr = multipletests(all_distance, alpha=0.05, method='bonferroni')\n",
    "print(\"DISTANCE (atar, rrt)\")\n",
    "print(distance_corr)\n",
    "print(\"___________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a433d-5d4d-454d-aa9f-2e5b6d8fff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "same = 0\n",
    "same_distance = 0\n",
    "for i in start_ends:\n",
    "    asp = paths['astar'][i]['trajectory']\n",
    "    swp = paths['spike'][i]['trajectory']\n",
    "    if asp == swp:\n",
    "        same += 1\n",
    "    if len(asp) == len(swp):\n",
    "        same_distance += 1\n",
    "\n",
    "print(f\"Number of identical paths: {same} of {len(start_ends)}. {same/len(start_ends) * 100:0.2f}%\")\n",
    "print(f\"Number of paths with identical distance: {same_distance} of {len(start_ends)}. {same_distance/len(start_ends) * 100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff4f22-b278-40f9-8e64-9d05275b7e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
